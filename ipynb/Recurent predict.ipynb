{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import gc\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from baseline import build_base_dataset\n",
    "from m5.metric import WRMSSE\n",
    "from m5.constants import *\n",
    "from m5.funcs import only_days_columns\n",
    "from utils.dtype import downcast\n",
    "from baseline import window_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format=\"[%(asctime)s] %(levelname)s: %(message)s\")\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = build_base_dataset()\n",
    "ds = ds[ds['d'] > 1380]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = WRMSSE(ds[ds['d'] < 1914], ds[ds['d'] >= 1914])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# затираем реальные продажи и цену, дабы не ликнуть данные\n",
    "ds['sold'] = ds['sold'].astype(np.float32)\n",
    "ds.loc[:, 'target_sold'] = ds.loc[:, 'sold']\n",
    "ds.loc[ds['d'] >= 1914, 'sold'] = np.nan\n",
    "ds['sell_price'] = ds['sell_price'].astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка набора данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Исключение данных \"до старта продаж\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# определяем стартпродаж по критерию - как только был продана хотяб 1 единца - старт т наступил\n",
    "ds['start_of_sales'] = ds.groupby('id')['sold'].transform(lambda x: np.argmax(x > 0))\n",
    "# поскольку сдвиг агрегатов у нас минимум 28 дней, то сдвинем старт продаж на этот срок\n",
    "ds = ds[ds['d'] > (ds['start_of_sales'])].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['event_type_1'] = ds['event_type_1'].cat.add_categories('NaN').fillna('NaN')\n",
    "ds['event_name_1'] = ds['event_name_1'].cat.add_categories('NaN').fillna('NaN')\n",
    "ds['event_type_2'] = ds['event_type_2'].cat.add_categories('NaN').fillna('NaN')\n",
    "ds['event_name_2'] = ds['event_name_2'].cat.add_categories('NaN').fillna('NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['revenue'] = ds['sold'] * ds['sell_price']\n",
    "ds['holliday_tommorow'] = ((ds['event_type_1'] != 'NaN') | (ds['event_type_2'] != 'NaN')).shift(-1).fillna(False).astype('int')\n",
    "\n",
    "ds['wday'] = ds.date.dt.weekday.astype('int16')\n",
    "ds['week'] = ds.date.dt.weekofyear.astype('int16')\n",
    "ds['month'] = ds.date.dt.month.astype('int16')\n",
    "ds['quarter'] = ds.date.dt.quarter.astype('int16')\n",
    "ds['year'] = ds.date.dt.year.astype('int16')\n",
    "ds['mday'] = ds.date.dt.day.astype('int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ds[(ds['d'] < 1914)]\n",
    "val_ds = ds[(ds['d'] >= 1914)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_features(ds: pd.DataFrame):\n",
    "    group_by_id = ds.groupby('id')\n",
    "    features = pd.DataFrame({\n",
    "        'id': ds['id'],\n",
    "        'item_id': ds['item_id'],\n",
    "        'd': ds['d'],\n",
    "        'sold_shift_1': group_by_id['sold'].shift(1),\n",
    "        'sold_shift_7': group_by_id['sold'].shift(7),\n",
    "        'price_diff_1': group_by_id['sell_price'].diff(),\n",
    "        'price_diff_7': group_by_id['sell_price'].diff(7),\n",
    "    })\n",
    "    \n",
    "    group_by_id = features.groupby('id')\n",
    "    features['rmean_s1_w7'] = group_by_id['sold_shift_1'].transform(lambda x: x.rolling(7).mean())\n",
    "    features['rmean_s1_w7'] = group_by_id['sold_shift_1'].transform(lambda x: x.rolling(28).mean())\n",
    "    features['rmean_s7_w28'] = group_by_id['sold_shift_7'].transform(lambda x: x.rolling(7).mean())\n",
    "    features['rmean_s7_w28'] = group_by_id['sold_shift_7'].transform(lambda x: x.rolling(28).mean())\n",
    "    \n",
    "    features = features.drop(['id', 'item_id', 'd'], axis=1)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "features = calculate_features(train_ds)\n",
    "new_features_col = features.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = pd.concat([train_ds, features], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL_FEATURES = [\n",
    "    'item_id', 'store_id', 'cat_id', 'state_id', 'dept_id',\n",
    "    'event_name_1', 'event_name_2', 'event_type_1', 'event_type_2',\n",
    "    'snap_CA', 'snap_TX', 'snap_WI',\n",
    "    'week', 'wday', 'month', 'mday',\n",
    "    'holliday_tommorow'\n",
    "]\n",
    "\n",
    "NUMERICAL_FEATURES = new_features_col\n",
    "\n",
    "XS = CATEGORICAL_FEATURES + NUMERICAL_FEATURES\n",
    "TARGET = 'target_sold'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'poisson',\n",
    "    'num_iterations': 2000,\n",
    "    'learning_rate': 0.075,\n",
    "    'verbose': 20,\n",
    "    'bagging_fraction': 0.5,\n",
    "    'feature_fraction': 0.7,\n",
    "    'metric': ['rmse'],\n",
    "    'min_data_in_leaf': 50,\n",
    "    'max_depth': 7\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_ds = train_ds.dropna(subset=XS + [TARGET])\n",
    "train, val = train_test_split(train_ds, test_size=0.1, random_state=42)\n",
    "train.shape, val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "field = 'constant_id'\n",
    "for idx_ in ds[field].unique().tolist():\n",
    "    logging.info(f'Train with {field} = {idx_}')\n",
    "    \n",
    "    cat_train = train[train[field] == idx_]\n",
    "    cat_train = cat_train[XS + [TARGET]].dropna()\n",
    "    cat_val = val[val[field] == idx_]\n",
    "    cat_val = cat_val[XS + [TARGET]].dropna()\n",
    "    logging.debug(f'Shape of train set: {cat_train.shape}')\n",
    "    logging.debug(f'Shape of valid set: {cat_val.shape}')\n",
    "\n",
    "    cat_train_set = lgb.Dataset(cat_train[XS], cat_train[TARGET])\n",
    "    cat_valid_set = lgb.Dataset(cat_val[XS], cat_val[TARGET])\n",
    "\n",
    "    logging.info('Starting model train')\n",
    "    evals_result = {}\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_set=cat_train_set,\n",
    "        valid_sets=[cat_train_set, cat_valid_set],\n",
    "        early_stopping_rounds=10,\n",
    "        categorical_feature=CATEGORICAL_FEATURES,\n",
    "        evals_result=evals_result,\n",
    "        verbose_eval=20 \n",
    "    )\n",
    "    models[idx_] = {\n",
    "        'model': model,\n",
    "        'evals_result': evals_result\n",
    "    }\n",
    "    logging.info('The model is trained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(\n",
    "    sorted(\n",
    "        sorted(zip(model.feature_importance(importance_type='gain'), model.feature_name()))\n",
    "    ),\n",
    "    columns=['values', 'names']\n",
    ")\n",
    "feature_importances = feature_importances.sort_values(by='values', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.barplot(x='values', y='names', data=feature_importances.head(50))\n",
    "plt.title('Общий график значимости ТОП-50 признаков (LightGBM gain)')\n",
    "plt.ylabel('Название признака')\n",
    "plt.xlabel('Важность (Gain)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb.plot_metric(evals_result, metric='rmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_model('recurent.lgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_lag = 36\n",
    "days = [x for x in range(1914, 1941 + 1)]\n",
    "val_pred = ds[ds['d'] >= (1914 - max_lag)].reset_index(drop=True)\n",
    "val_pred.loc[val_pred['d'] >= 1914, 'sold'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for day in tqdm(days):\n",
    "    local_ds = val_pred[val_pred['d'].between(day - max_lag, day)]\n",
    "    features = calculate_features(local_ds)\n",
    "    ds_for_predict = pd.concat([local_ds, features], axis=1)\n",
    "    for_predict = ds_for_predict.loc[ds_for_predict['d'] == day, :]\n",
    "    for idx_, model_dict in models.items():\n",
    "        model = model_dict['model']\n",
    "        for_predict_cat = for_predict.loc[for_predict[field] == idx_]\n",
    "        predict = model.predict(for_predict_cat[model.feature_name()])\n",
    "        val_pred.loc[(val_pred['d'] == day) & (val_pred[field] == idx_), 'sold'] = predict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = val_pred[val_pred['d'] >= 1914]\n",
    "predict['d'] = predict.d.apply(lambda x: f'd_{x}')\n",
    "predict = predict.pivot(index='id', columns='d', values='sold')\n",
    "predict = val_pred.loc[val_pred['d'] >= 1914, ID_COLUMNS].drop_duplicates().merge(predict, on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric.score(predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Отправка сабмита"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_days = only_days_columns(val_pred)\n",
    "submit_evaluation = val_pred[['id'] + submit_days]\n",
    "submit_rename_dict = {\n",
    "    col: f'F{i}' \n",
    "    for i, col in enumerate(only_days_columns(submit_evaluation), start=1)\n",
    "}\n",
    "submit_evaluation = submit_evaluation.rename(columns=submit_rename_dict)\n",
    "\n",
    "submit_validation = submit_evaluation.copy()\n",
    "submit_validation['id'] = submit_validation.id.str.replace('evaluation', 'validation')\n",
    "\n",
    "submit = pd.concat([submit_evaluation, submit_validation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('submit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c m5-forecasting-accuracy -f submit.csv -m \"Daily predict\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
